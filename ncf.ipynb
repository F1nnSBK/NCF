{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "394f2900",
   "metadata": {},
   "source": [
    "# Collaborative Filtering mit NCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e145e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import json\n",
    "import hyperparameter_opt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from ncf_training.trainer.utils.ncf import NCF\n",
    "from utils.interactions_dataset import InteractionsDataset\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7f050",
   "metadata": {},
   "source": [
    "## 1. Datenvorbereitung\n",
    "\n",
    "#### 1.1 Datenaufbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ac8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_csv(\"data/ncf_data_v2.csv\")\n",
    "data = data.drop_nulls()\n",
    "#data = data.sample(n=1_000_000, seed=42)\n",
    "print(data[\"user_pseudo_id\"].n_unique(), \"unique users\")\n",
    "print(data[\"article_id\"].n_unique(), \"unique items\")\n",
    "print(data.shape, \"rows in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156c2d70",
   "metadata": {},
   "source": [
    "#### 1.2 Trainings & Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa30c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data.to_pandas(), test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = pl.from_pandas(train_df)\n",
    "test_df = pl.from_pandas(test_df)\n",
    "\n",
    "print(\"Training DataFrame:\")\n",
    "print(train_df.shape)\n",
    "\n",
    "print(\"\\nTest DataFrame:\")\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a92990",
   "metadata": {},
   "source": [
    "#### 1.3 Konvertierung zu PyTorch Tensoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87afb99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = InteractionsDataset(train_df)\n",
    "test_dataset = InteractionsDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "num_users = len(train_dataset.user_id_map)\n",
    "num_items = len(train_dataset.item_id_map)\n",
    "print(f\"Number of users: {num_users}\\nNumber of items: {num_items}\")\n",
    "\n",
    "user_id_map = train_dataset.user_id_map\n",
    "item_id_map = train_dataset.item_id_map\n",
    "\n",
    "with open('user_id_map.json', 'w') as f:\n",
    "    json.dump(train_dataset.user_id_map, f)\n",
    "\n",
    "with open('item_id_map.json', 'w') as f:\n",
    "    json.dump({v: k for k, v in train_dataset.item_id_map.items()}, f)\n",
    "\n",
    "print(\"Mappings wurden als user_id_map.json und item_id_map.json gespeichert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78dedfe",
   "metadata": {},
   "source": [
    "## 2. Modelltraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a231db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NCF(num_users, num_items, embedding_dim=32, layers=[128, 64, 32]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "num_epochs = 10\n",
    "epoch_data = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for user_idxs, item_idxs in train_loader:\n",
    "        user_idxs_pos, item_idxs_pos = user_idxs.to(device), item_idxs.to(device)\n",
    "        labels_pos = torch.ones(len(user_idxs_pos), device=device)\n",
    "\n",
    "        neg_items = torch.randint(0, num_items, size=(len(user_idxs) * 4,), device=device)\n",
    "        user_idxs_neg = user_idxs.repeat_interleave(4).to(device)\n",
    "        item_idxs_neg = neg_items.to(device)\n",
    "        labels_neg = torch.zeros(len(user_idxs_neg), device=device)\n",
    "\n",
    "        combined_user_idxs = torch.cat([user_idxs_pos, user_idxs_neg], dim=0)\n",
    "        combined_item_idxs = torch.cat([item_idxs_pos, item_idxs_neg], dim=0)\n",
    "        combined_labels = torch.cat([labels_pos, labels_neg], dim=0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(combined_user_idxs, combined_item_idxs)\n",
    "        loss = criterion(outputs.view(-1), combined_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    epoch_data.append(total_loss / len(train_loader))\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd36f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(x=range(1, num_epochs + 1), y=epoch_data, marker='o')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(range(1, num_epochs + 1))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a837fe8",
   "metadata": {},
   "source": [
    "## 3. Evaluierung auf Basis des nDCG@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdad520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(scores, k=10):\n",
    "    \"\"\"Calculate Discounted Cumulative Gain (DCG) at k.\"\"\"\n",
    "    if len(scores) == 0:\n",
    "        return 0.0\n",
    "    scores = np.array(scores[:k])  # Ensure scores is a numpy array\n",
    "    return np.sum((2**scores - 1) / np.log2(np.arange(2, scores.size + 2)))\n",
    "\n",
    "def ndcg_at_k(truth, scores, k=10):\n",
    "    \"\"\"Calculate Normalized Discounted Cumulative Gain (nDCG) at k.\"\"\"\n",
    "    best_dcg = dcg_at_k(sorted(truth, reverse=True), k)\n",
    "    actual_dcg = dcg_at_k([truth[i] for i in np.argsort(scores)[::-1]], k)\n",
    "    return actual_dcg / best_dcg if best_dcg > 0 else 0\n",
    "\n",
    "user_id_map = train_dataset.user_id_map\n",
    "item_id_map = train_dataset.item_id_map\n",
    "\n",
    "train_df = train_df.with_columns(\n",
    "    pl.col(\"user_pseudo_id\").map_elements(lambda x: user_id_map.get(x), return_dtype=pl.Int64).alias(\"user_id_map\"),\n",
    "    pl.col(\"article_id\").map_elements(lambda x: item_id_map.get(x), return_dtype=pl.Int64).alias(\"item_id_map\")\n",
    ")\n",
    "\n",
    "test_df = test_df.with_columns(\n",
    "    pl.col(\"user_pseudo_id\").map_elements(lambda x: user_id_map.get(x), return_dtype=pl.Int64).alias(\"user_id_map\"),\n",
    "    pl.col(\"article_id\").map_elements(lambda x: item_id_map.get(x), return_dtype=pl.Int64).alias(\"item_id_map\")\n",
    ")\n",
    "\n",
    "test_users = test_df[\"user_id_map\"].unique()\n",
    "user_history_df = train_df.group_by(\"user_id_map\").agg(\n",
    "    pl.col(\"item_id_map\").alias(\"item_id_map_list\")\n",
    ")\n",
    "user_history = dict(zip(user_history_df[\"user_id_map\"], user_history_df[\"item_id_map_list\"]))\n",
    "\n",
    "model.eval()\n",
    "ndcg_scores = []\n",
    "with torch.no_grad():\n",
    "    for user_id in test_users:\n",
    "        if user_id is None:\n",
    "            continue\n",
    "        pos_items = test_df.filter(pl.col(\"user_id_map\") == user_id)[\"item_id_map\"].to_list()\n",
    "        pos_items = [item for item in pos_items if item is not None]\n",
    "\n",
    "        if not pos_items:\n",
    "            continue\n",
    "\n",
    "        user_interacted_items = set(user_history.get(user_id, []))\n",
    "\n",
    "        neg_items = []\n",
    "        while len(neg_items) < 99:\n",
    "            neg_item = np.random.randint(0, num_items -1)\n",
    "            if neg_item not in user_interacted_items and neg_item not in pos_items and neg_item not in neg_items:\n",
    "                neg_items.append(neg_item)\n",
    "\n",
    "        all_items = pos_items + neg_items\n",
    "\n",
    "        true_scores = np.zeros(len(all_items))\n",
    "        true_scores[:len(pos_items)] = 1\n",
    "\n",
    "        user_tensor = torch.LongTensor([user_id] * len(all_items)).to(device)\n",
    "        item_tensor = torch.LongTensor(all_items).to(device)\n",
    "\n",
    "        scores = model(user_tensor, item_tensor).cpu().numpy().flatten()\n",
    "\n",
    "        ndcg_scores.append(ndcg_at_k(true_scores, scores, k=10))\n",
    "\n",
    "average_ndcg = np.mean(ndcg_scores)\n",
    "print(f\"Mean nDCG@10: {average_ndcg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
